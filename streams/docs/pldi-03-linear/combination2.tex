%  could replace ``filter'' by ``stream'' in the next few sentences, but 
% I think it reads better as it is, actually
\section{Combining Linear Filters}
A primary benefit of linear filter analysis is that neighboring
filters can be collapsed into a single matrix representation if both
of the filters are linear.  This transformation automatically
eliminates redundant computations in linear sections of the stream
graph, thereby allowing the programmer to write simple, modular
filters and leaving the combination to the compiler.  In this section,
we first describe a {\it linear expansion} operation that serves as a
building block for the combination techniques.  We then give rules for
collapsing {\tt pipeline}s and {\tt splitjoin}s into linear nodes; we
do not yet deal with {\tt feedbackloop}s as they require the notion of
``linear state'' (see Future Work).

\subsection{Linear Expansion}

In StreamIt, the input and output rates of each {\tt filter} in the
stream graph are known at compile time.  The StreamIt compiler
leverages this information to compute a static schedule--that is, an
ordering of the node executions such that each filter will have enough
data available to atomically execute its {\tt work} function, and no
buffer in the stream graph will grow without bound in the steady
state.  A general method for scheduling StreamIt programs is given by
Karczmarek~\cite{karczma-thesis}.

A fundamental aspect of the steady-state schedule is that neighboring
nodes might need to be fired at different frequencies.  For example,
if there are two {\tt filters} $F_1$ and $F_2$ in a {\tt pipeline} and
$F_1$ produces $2$ elements during its {\tt work} function
($u_{F_1}=2$) but $F_2$ consumes $4$ elements ($e_{F_2}=4$), then it
is necessary to execute $F_1$ twice for every execution of $F_2$.

%% \begin{figure}
%% \center
%% \epsfxsize=3.0in
%% \epsfbox{images/expanding-a-filter.eps}
%% \caption{Expanding {\tt stream} $S$ by a factor $f$}
%% \label{fig:expanding-a-filter}
%% \vspace{-12pt}
%% \end{figure}

Consequently, when we combine hierarchical structures into a linear
node, we often need to {\it expand} a matrix representation to
represent multiple executions of the corresponding stream.  If we
expand a linear node by a factor of $k$, then one execution of the new
node will be exactly equivalent to $k$ executions of the original.

\begin{definition} (Linear expansion)
Given a linear node $\lambda = \{A, b, e, o, u\}$, the expansion of
$\lambda$ by a factor of $k$ is given by $\mbox{\bf expand}(\lambda, k) =
\{A', b', e', o', u'\}$, where: \\ ~ \vspace{-6pt} \\
\begin{tabular}{rl}
$e'$ & $= e + (k-1) * o$ \\ ~ \vspace{-10pt} \\
$o'$ & $= k * o$ \\ ~ \vspace{-10pt} \\
$u'$ & $= k * u$ \\ ~ \vspace{-10pt} \\
$A'$ & \raisebox{-14pt}{\parbox{3in}{is created by starting with a zero
matrix with $e'$ rows and $u'$ columns.  $A$ is then copied $k$ times
along the diagonal. Starting at the top left, each copy of $A$ is
offset from the previous copy by $u$ columns and $o$ rows.}} \\ ~ \vspace{-8pt} \\
$b'$ & is a row vector containing $k$ adjacent copies of $b$.
\end{tabular}

\end{definition}
Figure~\ref{fig:expanding-a-matrix} illustrates linear expansion.

\begin{figure}
\center
\epsfxsize=3.0in
\epsfbox{images/expanding-a-matrix.eps}
\caption{Expanding a linear node by factor $k$.}
\label{fig:expanding-a-matrix}
\vspace{-12pt}
\end{figure}

\subsection{Pipelines}

\begin{figure}
\center
\epsfxsize=3.0in
\epsfbox{images/pipeline-combination.eps}
\caption{A {\tt pipeline} of two linear forms $(A,b)$ and $(C,d)$ (above) and the same {\tt pipeline} with rate matched forms (below).}
\label{fig:combining-pipeline}
\vspace{-12pt}
\end{figure}

Serial combinations of {\tt streams} are formed with {\tt pipelines}.
Combining a {\tt pipeline} with an arbitrary number of linear forms
can be accomplished by continually combining adjacent pairs until a
single linear form remains.  The method for combining a single pair of
linear forms, $l_1=(A_1,b_1)$ and $l_2=(A_2,b_2)$ follows directly
from the equations relating the inputs and the outputs of the two
linear forms. Defining our notation: $l_1$ takes $x$ as input and
produces $y_1[n]$ as output. $l_2$ inputs $y_1$ and produces $y_2$ as
output.  Using our linear input to output equations from above, $y_1 =
xA_1 + b_1$ and $y_2 = y_1A_2 + b_2$. Combining the two previous
equations, $y_2 = xA_1A_2 + (b_1A_2 + b_2)$ which corresponds to a new
linear form $l'=(A_1A_2, b_1A_2+b_2)$ which computes $y_2$ directly
from $x$.

Because the expressions for $l'$ are matrix equations, the dimensions
of $A_1$ and $A_2$ might not be compatible for general programs.  The
problem of incompatible matrix sizes is the same problem of scheduling
execution such that the first {\tt stream} produces enough data for
the second {\tt stream} to read. To make the dimensions match up, we
use the $expand$ operation. We choose expansion factors $f_1$ and
$f_2$ such that $l_1' = expand(l_1,f_1) = (A_1',b_1')$ and $l_2' =
expand(l_2,f_2) = (A_2',b_2')$.  The equation $f_1u_{l_1}$ = $e_{l_2}
+ (f_2-1)o_{l_2}$ must hold, where $u_{lf_1}$, $e_{lf_2}$, and
$o_{lf_2}$ are program defined integers. Rewriting, we obtain
$(u_{l_1})f_1 + (-o_{l_2})f_2 = (e_{l_2}-o_{l_2})$ which is in the
form of the Diophantine equation $ax+by=c$ with $f_1=x$ and $f_2=y$. A
solution can be found using the Euclidean algorithm if
$gcd(u_{l_1},-o_{l_2})$ divides
$e_{l_2}-o_{l_2}$\cite{theory-of-numbers}. Once we have determined
$f_1$ and $f_2$ such that we can multiply $A_1'A_2'$, we are
guaranteed the be able to multiply $b_1'A_1'$.
Figure~\ref{fig:combining-pipeline} shows graphically the process of
expanding two linear forms in a {\tt pipeline} so that they can be
combined into a single linear filter.

% not clear if this is still important

However, in general problems, this constraint is not always satisfiable. For instance if
$u_{l_1}=2$, $e_{l_2}=3$ and $o_{l_2}=2$, there are pair of integers $f_1$ and $f_2$ to 
satisfy the above equation. Due to the buffering between the filters, we can not generate an 
overall linear form that represents the pair's computation except by introducing redundant
computation. However, by recognizing that the output from the first execution of the structure
can be written as a linear form $l'_i$, and that the output from each subsequent execution
of the structure can be written as a linear form $l'_j$ we can store the two linear forms $l'_i$ and
$l'_j$ which represent the initial execution and each subsequent execution respectively.

In some cases the combined linear form
actually represents a less efficient way of computing the results of the
filters. Specifically, when the number of non zero entries of $A_1'A_2'$ is greater
than the number of non zero entries $A_1'$ plus the non zero entries of $A_2'$, the overall
representation requires more computation.


\subsection{SplitJoins}
{\tt splitjoin}s allow a StreamIt programmer to express explicitly parallel computation. 
Data elements that arrive at the {\tt splitjoin} are directed
to the parallel sub {\tt streams} in one of two ways.
The simpler of the two is to send copy of each data element to the each of the sub {\tt streams}. 
The second of the two is specified by $N$ weights, $v_k$ for $k\in[0..N-1]$, 
where $N$ is the number of sub {\tt streams} in the {\tt splitjoin}. The first $v_0$ data elements
are sent to the leftmost {\tt Stream}. The next $v_1$ elements are sent 
to the next {\tt stream} and so on. When all $\sum_{k=0}^{N-1} v_k$ elements
have been seen, the splitter starts the same pattern over again.

The data from the parallel {\tt streams} are combined back into a single stream by means of
a joiner specified by weights $w_k$ for $k\in[0..N-1]$. First, $w_0$ items from the output tape of the 
leftmost {\tt stream} are placed onto the overall output tape, then 
$w_1$ elements are taken from the second leftmost {\tt stream} and so on. 
Again, the process repeats itself after one complete set of $\sum_{k=0}^{N-1} w_k$ 
elements has been pushed.

If we know that all subcomponents of a {\tt splitjoin} 
have linear representations, then we can describe the action of the entire {\tt splitjoin} 
with a single linear representation.
{\tt splitjoin}s containing all linear components are not as infrequent as they might seem -- 
most {\tt splitjoin} sub {\tt streams} often perform very similar computations, so when one 
is linear there is a high probability that all linear.

The joiner of a {\tt splitjoin} specifies a specific order of the output data 
that is produced by the parallel {\tt stream} blocks. Because each column 
of a linear representation's matrix represents the formula for calculating a single output value, 
the overall linear representation of a combined {\tt splitjoin} will be exactly 
the same columns of the parallel {\tt streams} in an ordering that depends on the joiner weights $w_i$.

Below we will describe the combination rules for a {\tt splitjoin}
with a duplicate splitter. Then we will describe how we can transform 
a roundrobin splitter {\tt splitjoin} into a duplicate splitter {\tt splitjoin}. 


\subsubsection{Duplicate Splitter}

\begin{figure}
\center
\epsfxsize=3.0in
\epsfbox{images/splitjoin-duplicate-ratematch.eps}
\caption{Expanding sub {\tt streams} to match their output rates in a linear {\tt SplitJoin}.}
\label{fig:splitjoin-duplicate-ratematch}
\end{figure}

In the following discussion, we focus on the matrix $A$ of a linear representation.
The operations for the constant vector $a$ occur in a very similar way.

Each row in the matrix $A$ of a linear form corresponds to the
weight associated with a particular input item. For a duplicate splitter,
the same rows in the sub matrices correspond to the same
input so long as the number of rows in the sub matrices are the same.

We wish to produce an overall representation by determining the correct
ordering the columns of the sub {\tt stream}' linear representations. We
need the number of rows to be the same, the total number of columns 
from all the sub matrices to equal some multiple of $\sum_{i=0}^{N-1}w_i$
and we need all of the sub linear forms to have the same $o$. 

If the joiner is ``run'' an integer number of times it needs to consume in aggregate
the exact number of items produced by an integer number of firings of
each sub {\tt stream}. To guarantee that there are never any ``spare'' columns,
we expand each of the sub {\tt streams} $F_i$ by a factor $f_i$.

Let $x=lcm(\forall k, lcm(u_{F_k},w_k))$, which is the $lcm$ of the $lcm$s of 
the push rates and the joiner weights. $x$ is the total number of elements that 
produced by a {\tt splitjoin} whose output is the same as the original but each 
of its sub {\tt streams} can be executed an integer number of times so that 
the joiner executes an integer number of times.

Therefore the appropriate expansion factors are  $f_i=\frac{x}{u_{F_i}}$ 
$F''_i = expand(F_i,f_i)$ will produce $f_i*u_{F_i}$ items, and it will take 
exactly $f_{w_i}=\frac{x}{w_i}$ firings of the 
joiner (each of which consumes $w_i$ elements), to consume all $f_iu_i$ items produced by $F''_i$.
It is important to note that we require that the {\tt splitjoin} does not need
infinite buffer space to schedule see \cite{karczma-thesis} for an explanation of schedules. 
For valid {\tt splitjoin}s $f_w=f_{w_i}$ is constant for all $i$. We also require that $o=o_{F''_i}$
constant for all $i$. Figure~\ref{fig:splitjoin-duplicate-ratematch} depicts the 
combination process graphically.

\begin{figure}
\center
\epsfxsize=3.0in
\epsfbox{images/splitjoin-duplicate-matrix.eps}
\caption{Matrix resulting from combining a {\tt splitjoin} of rate matched sub {\tt streams}.}
\label{fig:splitjoin-duplicate-matrix}
\end{figure}

After the rates are matched as described above, we are guaranteed to have the same number of rows
in each of the expanded sub representations. To construct the overall matrix, $A'''$, 
all that remains is to order the columns of the expanded representations appropriately. 
First we create $A'''$ which has $e_{F''_i}$ rows (which is the same for all $i$) and has 
$f_w(\sum_{i=0}^{N-1}w_i)$ columns. 
%We know that the first $w_0$ output elements of the overall {\tt splitjoin} will be the first $w_0$ output elements from $F''_1$. 
We place the $w_0$ rightmost columns of $A''_0$ as the $w_0$ rightmost 
columns of $A'''$. We then place the $w_1$ rightmost columns of $A''_1$ into the next $w_1$ columns 
of $A'''$, and so forth. When we have placed $\sum_{i=0}^{N-1}w_{i}$ (the number of outputs resulting from 
completely executing the joiner once), we start the process again from the beginning (taking the remaining
rightmost $w_0$ columns from $A''_0$, etc) until all of the columns from the expanded representations have
been fitted into $A'''$. Figure~\ref{fig:splitjoin-duplicate-matrix} graphically depicts the process of 
creating the overall $A'''$ from the smaller $A''_i$s.



\subsubsection{Roundrobin Splitter}

In the case of roundrobin splitters, data is directed to the various sub {\tt streams} 
according to weights $v_i$: the first $v_0$ input elements are directed to $F_0$, the next
$v_1$ elements are directed to $F_1$, etc. If the sub {\tt streams} are
all linear, we can determine an overall linear representation given the same
assumptions of finite buffer requirements, and uniform $o_i$.
Our strategy is to transform the splitter from roundrobin to duplicate by
modifying the sub {\tt stream}s' linear representations. 

Because the splitter is a roundrobin and not a duplicate, the same rows of the sub 
{\tt stream}s' representation matrices do not represent the same input elements 
even when the sub {\tt stream}s' representations are the same size. 
The same rows don't represent the same data because each {\tt stream} 
doesn't see any of the data directed to any other {\tt stream}. Therefore simply 
arranging columns as described above will not produce a correct overall linear representation. 

\begin{figure}
\center
\epsfxsize=3.0in
\epsfbox{images/splitjoin-roundrobin-matrix.eps}
\caption{Corresponding matrix for splitter conversion from roundrobin to duplicate.}
\label{fig:splitjoin-roundrobin-matrix}
\end{figure}

To perform the transformation from roundrobin to duplicate, the same rows
in each sub {\tt Stream}'s matrix must represent the same data items. Changing from splitjoin to 
duplicate implies that each sub {\tt streams} will be fed all of the input data. All data
that was nor originally bound for other {\tt stream}s needs to be ignored, which requires
changing the original {\tt stream}s $F_i$ to $F'_i$. In our linear
framework, we represent the independence of an output from an input as a zero in the appropriate
element of the linear representation matrix. Therefore, we transform $F_i$ to $F'_i$ by inserting
rows of zeros into linear representation of the sub {\tt streams} at positions such that
the data bound for another sub {\tt stream} is ignored. Each of the new matrices $F'_i$ 
has exactly $\sum_{i=0}^{N-1}v_i$ rows and the same number of columns of $F_i$, and 
$o_{F'_i}=o_{F_i}$.
Figure~\ref{fig:splitjoin-roundrobin-matrix} illustrates how the new matrix is constructed.
We have now transformed our {\tt splitjoin} with a roundrobin splitter into a {\tt splitjoin}
with a duplicate splitter which we know how to combine already.
