\section{Introduction}

We are approaching the juncture where transistors are essentially free
to the designer of a microprocessor.  Designers are now looking for
novel solutions to the wire delay problem. Recently the architecture
community has witnessed the ascendancy of communication-exposed
architectures, examples include Raw \cite{raw}, Smart Memories
\cite{smartmemories}, Merrimac \cite{merrimac-sc03}, TRIPS
\cite{trips}, WaveScalar \cite{wavescalar}, and RDR \cite{rdr}.  These
machines propose to solve the wire delay problem by replicating
processing units and exposing the interconnect between these units to
a software layer.  For these architectures to gain programmer
acceptance, there must exist a high-level, portable programming
language that can be compiled efficiently to any of the candidate
targets.

A number of efforts have focused on stream programming as a paradigm
for producing high-level, efficient, and retargetable application code
for wire-exposed architectures \cite{streamit-asplos,imagine-ieee,merrimac-sc03,trips-isca03}.
In a stream program, computation is expressed as a set of filters that
operate over sequences of data.  Because each filter has an
independent address space and program counter, there is abundant task
and data parallelism that can be recognized by the compiler.  Also,
the data streams expose the communication between filters; the
compiler can predict the flow of data and orchestrate data movement.
These properties distinguish stream programs from imperative languages
such as C and FORTRAN.  While imperative languages were a good match
for von-Neumann machines, they are obsolete for architectures
containing multiple instruction streams and distributed memory banks.

Hitherto, there have been two basic approaches for compiling a stream
program to a communication-exposed architecture.  {\it Time
multiplexing} utilizes the entire chip for each filter, switching
between filters over time (see Figure~\ref{fig:spacevstime}b).  Time
multiplexing's efficacy extends from its freedom from having to
balance the workload between filters.  However, this technique can
lead to long latencies, increased memory traffic, and the utilization
is highly dependent upon how effectively each filter can be
parallelized across the machine.

Conversely, {\it space multiplexing} distributes filters across the
entire chip, running them continuously and in parallel (see
Figure~\ref{fig:spacevstime}a).  Space multiplexing affords $(i)$ no
filter swapping, $(ii)$ reduced memory traffic, $(iii)$ localized
communication, and $(iv)$ tighter latencies.  Because it distributes
computation across decentralized processing units, space multiplexing
supports architectures that scale spatially without any global wires.
Unfortunately, this approach is highly dependent on effective load
balancing techniques: filters must be merged and split until all
computation resources are assigned a filter with a uniform workload.
Such load balancing can be very difficult for applications with an
irregular distribution of work.

This paper proposes a hybrid approach, {\it space-time multiplexing},
that exploits the advantages of both space multiplexing and time
multiplexing (see Figure~\ref{fig:spacevstime}c).  This technique uses
space multiplexing to schedule a group of filters for parallel
execution on part of the chip; however, time multiplexing is used to
switch between different groups as execution progresses.  Space-time
multiplexing affords the flexible load balancing of time multiplexing,
while preserving the locality and latency benefits of space
multiplexing.

\begin{figure}[t]
  \centering
  \vspace{-18pt}
  \psfig{figure=space-vs-time.eps,width=5.5in}
  \vspace{-12pt}
  \caption{Techniques for scheduling stream programs. \protect\label{fig:spacevstime}}
  \vspace{-6pt}
\end{figure}

In this paper, we describe and evaluate a fully-automatic
implementation of space-time multiplexing.  Our source language is
StreamIt~\cite{streamitcc}, a high-level stream programming language
that aims to be portable across next-generation communication-exposed
architectures.  Our target is the Raw
microprocessor~\cite{raw10,raw_isca}, a tiled architecture with
fine-grained, programmable communication between processors.  

Our implementation of space-time multiplexing treats each group of
space-multiplexed filters, which we refer to as a {\it trace}, as an
atomic unit for scheduling.  Traces can be scheduled using techniques
traditionally limited to individual instructions in a given loop nest.
Our approach extends these loop-level techniques---in particular,
software pipelining---to a coarse level of granularity that
encompasses multiple program modules at a time.

Also, since each trace is independent, a specific code generation
strategy can be applied depending on the properties of the trace.  In
this paper, we recognize traces that compute a {\it linear} function
of their input.  Using the coefficients and I/O rates of the linear
trace (extracted automatically from the code), we generate template
assembly code based on a hand-optimized systolic algorithm.  By
decoupling memory accesses from computation and carefully utilizing
the register-mapped communication network on Raw, this code achieves
near-optimal performance for linear functions.

In summary, this paper makes the following contributions:

\begin{itemize}
\item A procedure for eliminating synchronization from a hierarchical
stream graph, yielding a flat graph that directly exposes
communication patterns.
\item An algorithm for extracting load-balanced traces from a flat
stream graph.
\item An optimized code generation strategy for traces that compute a
linear function.
\item A modified software pipelining algorithm for scheduling traces,
respecting layout and occupancy constraints on a tiled architecture.
\item An evaluation of space-time multiplexing in the StreamIt-to-Raw
compiler, demonstrating an average improvement of \todo{??} over a
space multiplexing approach.
\end{itemize}

The remainder of this paper is organized as follows.  Section
\ref{sec:streamit} gives an introduction to the StreamIt programming
language and Section \ref{sec:raw} provides an overview of
Raw. Section~\ref{sec:example} gives an illustrative example for our
technique.  Sections 5 through 10 describe our compilation framework,
including synchronization removal, trace extraction and scheduling,
and code generation.  Section \ref{sec:results} presents our results,
Section \ref{sec:related} reviews related work and Section
\ref{sec:conclusion} concludes.

%% In this paper we present a compiler for the StreamIt programming
%% language \cite{streamitcc}.  StreamIt is a high-level stream
%% programming language that aims to be portable across next-generation
%% communication-exposed architectures.  StreamIt contains basic
%% constructs that expose the parallelism and communication of streaming
%% applications without depending on the topology or granularity of the
%% target architecture \cite{streamit-asplos}. In StreamIt the basic unit
%% of computation is a {\it filter}, a single-input, single-output block.
%% Filters are composed into a communication network using hierarchical,
%% structured constructs (introduced below).  A {\it stream graph},
%% composed of filters and uni-directional FIFO channels connecting the
%% filters, describes the resulting computation. The StreamIt compiler
%% currently targets the Raw microprocessor, a tiled architecture with
%% fine-grained, programmable communication between processors.

%% Neglecting the irrelevant initial passes, the flow of the compiler is
%% as follows.  The compiler reaches the space-time backend with a
%% structured, hierarchical stream graph, where all filters of the
%% application are explicitly represented.  We first convert this stream
%% graph into to a flat, non-hierarchical graph with unnecessary
%% communication channels removed.  Next, we identify the linear
%% sub-components of the stream graph.  Our compiler then extracts the
%% traces from the stream graph, considering the concurrency,
%% communication, layout, and type (linear or non-linear) of each filter.
%% Next, we schedule the traces, producing both a multi-stage initialization
%% schedule and a steady-state schedule.  Lastly, we generate both
%% communication and computation code for Raw.  The contributions of this
%% monograph include:
