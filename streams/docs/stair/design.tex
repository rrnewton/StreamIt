\documentclass[11pt]{article}

\usepackage{cite}
\usepackage[margin=1in]{geometry}
\usepackage{palatino}
\usepackage{url}

% Abstract formatting:
\def\class#1{\texttt{#1}}

% Print acronyms in small caps.
\def\dsp{\textsc{dsp}}
\def\fortran{\textsc{fortran}}
\def\ir{\textsc{ir}}
\def\Ir{\textsc{Ir}}
\def\mips{\textsc{mips}}
\def\mit{\textsc{mit}}
\def\opi{\textsc{opi}}
\def\raw{\textsc{raw}}
\def\scale{\textsc{scale}}
\def\sir{\textsc{sir}}
\def\ssa{\textsc{ssa}}
\def\Ssa{\textsc{Ssa}}
\def\stair{\textsc{stair}}
\def\Stair{\textsc{Stair}}
\def\suif{\textsc{suif}}
\def\Suif{\textsc{Suif}}
\def\suifvm{\texttt{suifvm}}
\def\vliw{\textsc{vliw}}
\def\xml{\textsc{xml}}
\def\Xml{\textsc{Xml}}
\def\machsuif{Machine \suif}

% Predefine useful email addresses.
\urldef\dmazemail\url{dmaze@cag.lcs.mit.edu}

\hyphenation{op-er-and op-er-ands}

\title{\Stair: StreamIt Target Architecture Intermediate
  Representation\\Design}
\author{David Maze\\\dmazemail}

\begin{document}

\maketitle
\tableofcontents

\section{Motivation}

StreamIt is a language for programs that process continuous streams of
input data, including audio processors and other signal-processing
applications.  For familiarity with students working on the project,
StreamIt uses the Kopi compiler\cite{kopi} as its base; this was the
only available Java compiler written in Java.  However, Kopi's only
``backend'' is for Java bytecode, and this is deeply twisted into the
innards of the compiler.  StreamIt's two existing backends, for
uniprocessor machines and \mit's \raw{} architecture, both work by
generating C code and using a native compiler.

The StreamIt group plans to extend the compiler to a number of
different architectures.  These include the low-power \mit{} \scale{}
project, Stanford's Imagine chip, and an off-the-shelf \dsp.  To make
effective use of these processors' features, a native-code backend is
required; for example, both \scale{} and Imagine have \vliw{} modes,
and the StreamIt compiler can add parallelism by unrolling or fusing
filters in ways that a C compiler might not be able to figure out.

This document describes \stair, a proposed system for writing generic
backends to the StreamIt compiler.  \Stair{} follows in the spirit of
\machsuif\cite{machsuif}, but is written in Java as a standalone
component to avoid several workarounds required by the C++ language
and the \suif~2 core.

\subsection{Related Work}

The Stanford University Intermediate Format, \suif\cite{suif,suif2},
has been around for some time.  The original \suif{} work focused on
parallelizing \fortran{} code.  \suif{} 2 was released more recently,
and uses a more Java-like \ir{} structure, but still focuses more on
high-level optimization.

Glenn Holloway's group at Harvard has developed a generic backend
system for \suif{} called \machsuif\cite{machsuif}.  Much of the
inspiration for the \stair{} design comes from this project.
\machsuif{} is built on top of \suif{} 2; backend nodes are actually
specialized \suif{} nodes, for example, and extending the backend
system involves understanding the \suif{} object scheme.  The
\machsuif{} documentation suggests that the system implements a
generic optimization programming infrastructure (\opi), but practical
use of the system involves knowing the internal design of the
\machsuif{} nodes and the underlying \suif{} implementation.

Kathryn McKinley and her group at the University of Massachusetts at
Amherst have developed a compiler infrastructure in Java called
Scale\cite{scale-umass}.  The Scale Web page suggests that most of
their work is aimed towards high-level optimization, but the package
includes a backend package with targets including the Alpha, \mips,
PowerPC, and Sparc processors.  Scale also includes a backend for the
University of Texas' Trips architecture, which outputs code for the
Trips Intermediate Language.  Scale appears to have one Java class per
variety of machine instruction, and machine specialization is
performed by creating objects of types specific to the target backend
package.  There is no generic notion of an operand as such; possible
operands are defined by the various per-instruction classes.

\section{Goals and Features}

\Stair{} has a diverse set of goals and considerations.  This section
lists the goals, considerations, and features \stair{} will
accomodate.

\subsection{Goals}

\begin{enumerate}
\item \textbf{Input.}  \Stair{} is immediately intended for
  use by StreamIt, and may have features specific to StreamIt.
  However, the design should not preclude a Java-to-native compiler
  based on Kopi, or more ambitiously, a Java-based C compiler.
\item \textbf{Outputs.}  \Stair{} should be able to generate
  machine-specific assembly, but it should also be able to generate C
  code to emulate the current uniprocessor backend and provide support
  for machines that we haven't necessarily written a native-code
  backend for yet.
\item \textbf{Targets.}  Various targets have different features that
  might require \ir{} support.  Intel's Itanium and other architectures
  have predication support, which requires a field in the \ir{} for the
  predicate.  \Ir{} support may also be necessary for various sorts of
  scheduling.
\item \textbf{Scheduling.}  We want to be able to accomodate various
  sorts of schedulers, and hopefully in a reasonably portable way.  It
  should be easy to reuse scheduler code for \scale's \vliw{} mode and
  Imagine, for example.  Scheduling information wants to be attached
  to individual instructions, and \ir{} support is needed to avoid
  e.g.~Fenway's ``bundle'' instructions\cite{fenway}.  Abstract code
  also needs to be able to determine if two instructions are
  dependent, and if they are scheduled, whether they are scheduled to
  execute simultaneously or not.
\end{enumerate}

\subsection{Features}

\begin{enumerate}
\item \textbf{XML text storage.}  It may be desirable to save an \ir{}
  to a file in a way that will be recoverable later, or to examine the
  \ir{} outside of the infrastructure.  \Xml{} provides a somewhat
  convenient and somewhat standard way of doing this.  The world
  likely contains browsers for \xml{} and Java tools to generate
  \xml{} for us, which saves some work.
\item \textbf{Single static assignment form.}  \Ssa{} form is useful for
  a reasonable number of algorithms; in particular, constant and copy
  propagation and dead code elimination become trivial after \ssa{} is
  run.  \Ssa{} has also become recently available as an add-on for
  \machsuif.  Base \ir{} support for \ssa{} should be included in \stair;
  however, always using \ssa{} adds some overhead, since the \ssa{}
  information needs to be recalculated if the \ir{} changes.
\item \textbf{Data-flow engine.}  One noticable lack in the existing
  StreamIt infrastructure is a generic data-flow engine.  Given a
  portable \ir{} based on a control-flow graph, this should be easy to
  create, simplifying the creation of new optimizations.
\end{enumerate}

\subsection{Issues}

\begin{enumerate}
\item \textbf{Initialized data.}  While StreamIt programs generally
  don't have a lot of initialized data, things like weight vectors are
  not inconceivable, and other languages definitely do.  \machsuif{}
  uses \suif's infrastructure for initialized data, rather than coming
  up with its own mechanism.
\item \textbf{Types.}  \Suif, and consequently \machsuif, is very
  typeful; every operand has a type which includes signedness and bit
  width.  This in practicate is more of an irritation than a feature:
  is a typical general-purpose register unsigned?  How many bits wide
  is the constant ``1''?  StreamIt only really has two primitive
  types, ``int'' and ``float'', with no specified width.  A simpler
  type scheme might work here, though we also may want to accomodate
  languages like \fortran{} where the language includes specific bit
  widths.
\item \textbf{Functions and larger bodies.}  \machsuif{} provides a
  ``function'' abstraction, and a file is made up of a list of
  functions.  At the level \stair{} will be used, this isn't
  necessarily appropriate, though it does make sense for a
  uniprocessor backend.  \Stair{} probably wants to provide a
  control-flow graph and a ``function'' abstraction, but leave
  higher-level organization of functions to the calling code.  In the
  particular case of StreamIt, \stair{} could replace Kopi for the
  bodies of functions in the \sir{}.
\end{enumerate}

\section{The Backend System}

\machsuif{} has a very useful treatment of per-processor backends.  An
input pass converts \suif{} 2 \ir{} nodes into \machsuif{} nodes,
using a virtual machine target called \suifvm.
Architecture-independent passes can then run on this layer.  Each
``real'' backend has a visitor that can visit \suifvm{} instructions
and generate target-specific instructions.  Other passes, notably
register allocation, then happen on the target-specific instructions.

A backend provides details about the target machine.  This includes
the possible set of opcodes, the available registers, and valid
instruction formats.  The architecture-independent virtual machine
concept seems like a useful one.  The backend needs to provide
information as required for the register allocator, and possibly other
specific passes, and may also need to provide default liveness
information for machine registers.

In \machsuif{}, a machine opcode is an integer, and the backend is
responsible for translating an integer opcode to a name.  It makes
somewhat more sense to make opcodes singleton objects, and in the
external representation treat them by name.  This avoids problems we
ran into with Fenway\cite{fenway} where changing the list of opcodes
invalidates any extant intermediate files on disk.  It also gives an
obvious place to ask about instruction formats and valid operands.
However, this comes at the cost of complicating the actual backend
code; this implementation requires a class per opcode, where
\machsuif{} could be satisfied with a couple of lists of properties.
The \machsuif{} model could actually be implemented with a single
\class{Generic\-Opcode} class that deferred questions to the backend,
so long as glue was provided to create the singleton objects.

\section{Classes}

\subsection{Instructions}

Fundamentally, a low \ir{} represents a program as a list of
instructions.  This suggests the following basic class for an
instruction:

\begin{verbatim}
public class Instruction {
  public Backend getBackend();

  public void setBlock(Block block);
  public Block getBlock();
  public void setLabel(String label);
  public String getLabel();
  public void setOpcode(Opcode opcode);
  public Opcode getOpcode();
  public List getSources();
  public void setSource(int n, Operand op);
  public int getNumSources();
  public Operand getSource(int n);
  public List getDests();
  public void setDest(int n, Operand op);
  public int getNumDests();
  public Operand getDest(int n);
  public void setPred(Operand op);
  public Operand getPred();
  public void setSched(Scheduling sched);
  public Scheduling getSched();
  public void setAnnotation(String key, Object annotation);
  public Object getAnnotation(String key);
}
\end{verbatim}

Every instruction has a pointer to its container; this implies that
instructions can't be shared.  An instruction is specialized for a
particular machine, and the opcode should come from the set of
instructions supported by the target.  Opcodes are objects (not
integers as in \machsuif); they should come from a factory object such
that there is a single object for each machine opcode.  Instructions
can have string-keyed annotations, where the annotation can be an
arbitrary object.  The label is a string that lists either the target
of a control-transfer instruction, if present, or the value of a label
instruction.

\subsection{Operands}

There are several conceivable sorts of operands.  These include
integer immediates, program variables, machine registers, and several
base-plus-offset combinations.  \machsuif{} has a reasonably extensive
set of these, including null, variable, physical register, virtual
register, integer immediate, string immediate, address-of-symbol,
base-displacement, base-symbol-displacement, base-index, and
symbol-displacement.  Having all of the various sorts of
indirect-address operands is only useful if real machines support
them; base-plus-index-times-scale-plus-displacement is the most
complex thing supported in \machsuif, but it is conceivable that this
exists on some processor architecture.

Useful operands can be classified:

\begin{itemize}
\item \textbf{Immediates.}  These should include integer and float
  immediates, and possibly character and string immediates too (though
  a character is conventionally an integer and a string initialized
  data).
\item \textbf{Variables.}  They probably come by reference to a symbol
  table.  Variable references as operands have an integer for the \ssa{}
  index within the current function.
\item \textbf{Registers.}  \machsuif's hard/virtual register
  distinction is useful; however, a virtual register is really just a
  special sort of anonymous variable.  ``Register'' should be reserved
  for a physical register.
\item \textbf{Addresses.}  Addresses can be complicated.  The simplest
  case is ``address of variable'', but a machine can have arbitrarily
  complicated hardware-supported addresses.  For example, on a 6502:
\begin{verbatim}
LDX $40
LDY $40
LDA (X),2
STA (Y,2)
\end{verbatim}
  loads the accumulator from ((address pointed to at address 0x40) plus
  2), and stores the result into (address pointed to at (address 0x40
  plus 2)).  One generic answer is to create a composite operand, with
  operations ``add'' and ``multiply'', and make ``dereference'' a
  separate operand type.
\item \textbf{Address-of-symbol.}
\item \textbf{Contents-of-address.}
\end{itemize}

Most of these have completely different contents, but we also want to
avoid descending into class-hierarchy hell.  Nevertheless, as an
immediate proposal, classes \class{Operand}, \class{Int\-Immediate},
\class{Float\-Immediate}, \class{Variable}, \class{Register},
\class{Address\-Of}, \class{Contents\-Of}, and
\class{Composite\-Address} supply the list of operands here.

A composite-address operand is a little tricky to use.  The intent is
that it only be used where it corresponds to a real machine
instruction.  This means that code like \verb|A[4]=6| for an integer
array would get translated into VM code

\begin{verbatim}
__temp_1 = address-of A
__temp_2 = mul 4, 4
__temp_3 = add __temp_1, __temp_2
__temp_4 = 6
           store __temp_3, __temp_4
\end{verbatim}

\noindent and then the backend code would be responsible for turning it back
into a single instruction if that were possible on the target machine.

One implication of this is that a back-end driver should be able to
run transformation passes on the VM code.  For example, a constant
folding pass followed by constant propagation and dead-code
elimination could remove the multiply instruction; trivial strength
reduction is also important.

\subsection{Backends}

\begin{verbatim}
public class Backend {
  public String getName();
  public Opcode getOpcode(String name);
  public boolean verifyInstruction(Instruction instr);

  public void insertSpill(ListIterator pos, Operand op);
  public void insertUnspill(ListIterator pos, Operand op);
  public void insertLabel(ListIterator pos, String target);
  public void insertUnconditionalBranch(ListIterator pos,
                                        String target);
  public void insertConditionalBranch(ListIterator pos,
                                      Operand cond, String target);
}
\end{verbatim}

As discussed above, a backend is a connection between the \ir{} and a
real machine architecture.  It contains a method for getting the
\texttt{Opcode} object corresponding to an opcode name, and to verify
that an instruction is valid.

Backends also contain methods to assist the register allocator.
\texttt{insert\-Spill()} and \texttt{insert\-Unspill()} insert store and
load instructions around a particular instruction.  These take a
\class{List\-Iterator} object that points immediately after the
instruction to be spilled; they can get the instruction by calling the
\texttt{previous()} method on the iterator, and use the iterator's
methods to insert spill/re\-store code.

The generic backend interface also contains methods needed to flatten
a control-flow graph.  Methods to insert labels and conditional and
unconditional branches insert instructions after the specified
iterator.  It is conceivable that a conditional branch, in particular,
might need to insert multiple instructions.

\subsection{Symbols and Symbol Tables}

A variable lives in a symbol table; a symbol table is associated with
the block it appears in.  ``Block'' here may actually be context
larger than a single function for files in the scope of a filter; it
is up to higher-level code to appropriately manipulate (rename,
rescope) variables depending on the desired output.

Symbols and registers, but nothing else, have types.\footnote{This may
  result in corner cases involving integer overflow being missed,
  though.}  A type has a primitive type, signed or unsigned integer or
float, and an optional bit-width.  Registers always have bit width.
Symbols may additionally have structured, union, and laid-out types.  A
structured type contains an ordered list of pairs of names and types,
corresponding to a C structure; a union type has an unordered list of
names and types corresponding to a C union.  A laid-out type has
explicit bit widths for its consituents, which have names, types, and
offsets within the structure.  Each of these types also has a
queryable size.

A symbol table then consists of just an unordered association between
names and types.  Global symbols will need to live forever, but also
have no interesting information beyond their name and type, possibly
including layout in the type.  Local symbols will be replaced by
registers in register allocation, and those that aren't will be
replaced by register memory references in a layout/finalization pass.

\subsection{Blocks}

With all of these components, we can assemble a basic block.  A block
contains a Java \class{List} of instructions and a symbol table.  For
\ssa{} form, each block also needs sets of live variables on entry and
exit.  Finally, since instruction sharing is prohibited, block sharing
can be too; thus, each block has a list of its predecessors and
successors, and a condition under which one successor would be chosen
over another, as well as the containing object.

A block container should be a Java interface:

\begin{verbatim}
public interface BlockContainer {
  public Block getEntry();
  public Block getExit();
}
\end{verbatim}

Edges between blocks should be classified as normal or impossible;
other classifications are possible.  An impossible edge exists from
the head of a loop to the exit of the container if there is no other
path from that point to the exit (in particular, a known-infinite
loop).

Ignoring multi-way branches (C switch statements), a block has an
arbitrary number of predecessors and exactly two successors.  However,
we want to consider other schemes, such as hyperblocks, where there
may be multiple exits from a trace block.  Similarly, multiple-entry
schemes should not be discarded out-of-hand.  Probably the best way to
describe where an entry or exit point is is with an
\class{Instruction} pointer, such that an entry is before the
specified instruction (or at the start of the block if \texttt{null}),
and an exit is after the specified instruction (or the end of the
block).  Maintaining these will be tricky if other optimizations
happen after block formation.

With this in mind, we get the following structure for a block:

\begin{verbatim}
public class Block {
  public List getBody(); // mutable list of Instruction
  public class Edge {
    public Block getTarget();
    public boolean isNormal();
    public boolean isImpossible();
    public Instruction getInstruction();
    public Operand getCondition();
  }
  public Edge makeEdgeTo(Block target, boolean normal,
                         Operand condition, Instruction instr);
  public List getPredecessors(); // mutable list of Edge
  public List getSuccessors(); // mutable list of Edge
};
\end{verbatim}

\section{Usage}

Currently the StreamIt compiler uses Kopi's high-level Java \ir{} for
its program representation.  After the input code is parsed, the
program is converted to a form called \sir{}, where stream
transformations happen.  For \raw{}, further stream transformations
are used to partition the stream graph; in both current backends, the
final output is C code.

I envision the following compiler flow for StreamIt:

\begin{enumerate}
\item \textbf{Frontend.}  Parse a StreamIt program.  Create the
  frontend data structures.
\item \textbf{Graph expansion.}  Within the frontend, perform constant
  propagation, unroll loops, and produce an expanded stream graph.
  This happens here since characteristics such as loop bounds should
  be easier to find in the input \ir.
\item \textbf{SIR construction.}  Convert the front-end stream graph
  to StreamIt \ir.  Use \stair{} for the bodies of functions.
\item \textbf{Stream transformations.}  Perform various stream
  transformations on \sir{} as the compiler currently does.
\item \textbf{Partitioning.}  As happens currently for \raw{} and
  other tiled architectures.  This may also do time partitioning if
  necessary.  If the target in \stair{} is known at this point, the
  backend object may be able to provide more efficient time estimates
  for operations.
\item \textbf{Native code generation.}  This uses \stair{} features to
  produce efficient code.
\end{enumerate}

This flow completely avoids Kopi.  The \sir{} construct for a filter
needs to include a \stair{} symbol table object for the filter's
fields.  What happens to this depends on the backend: in the
uniprocessor code, the fields would become a \stair{} structure type,
while on \raw{}, they would be promoted to per-tile global variables.

\bibliographystyle{plain}
\bibliography{references}

\end{document}